{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2023 a1147\n",
    "# \n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "# \n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "# \n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from torch import optim\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torchvision import transforms\n",
    "from torchvision.models import resnet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\a1147\\Documents\\projects\\cnn\\train.ipynb Cell 2\u001b[0m line \u001b[0;36m4\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/a1147/Documents/projects/cnn/train.ipynb#W1sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39m__getitem__\u001b[39m(\u001b[39mself\u001b[39m, index) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m (cv2\u001b[39m.\u001b[39mMat, \u001b[39mint\u001b[39m):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/a1147/Documents/projects/cnn/train.ipynb#W1sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata[index][\u001b[39m0\u001b[39m], \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata[index][\u001b[39m1\u001b[39m]\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/a1147/Documents/projects/cnn/train.ipynb#W1sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m train_dataset \u001b[39m=\u001b[39m MyDataset(\u001b[39m'\u001b[39;49m\u001b[39mtrain_datasets\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/a1147/Documents/projects/cnn/train.ipynb#W1sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m val_dataset \u001b[39m=\u001b[39m MyDataset(\u001b[39m'\u001b[39m\u001b[39mval_datasets\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;32mc:\\Users\\a1147\\Documents\\projects\\cnn\\train.ipynb Cell 2\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/a1147/Documents/projects/cnn/train.ipynb#W1sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m gauss \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mnormal(mean,sigma,img\u001b[39m.\u001b[39mshape)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/a1147/Documents/projects/cnn/train.ipynb#W1sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m noisy_img \u001b[39m=\u001b[39m img \u001b[39m+\u001b[39m gauss\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/a1147/Documents/projects/cnn/train.ipynb#W1sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m img \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mmoveaxis(img, \u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m, \u001b[39m0\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/a1147/Documents/projects/cnn/train.ipynb#W1sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m noisy_img \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mmoveaxis(noisy_img, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m0\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/a1147/Documents/projects/cnn/train.ipynb#W1sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mappend([img, \u001b[39m0\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\a1147\\miniconda3\\Lib\\site-packages\\numpy\\core\\numeric.py:1389\u001b[0m, in \u001b[0;36m_moveaxis_dispatcher\u001b[1;34m(a, source, destination)\u001b[0m\n\u001b[0;32m   1385\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mrepeated axis\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m   1386\u001b[0m     \u001b[39mreturn\u001b[39;00m axis\n\u001b[1;32m-> 1389\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_moveaxis_dispatcher\u001b[39m(a, source, destination):\n\u001b[0;32m   1390\u001b[0m     \u001b[39mreturn\u001b[39;00m (a,)\n\u001b[0;32m   1393\u001b[0m \u001b[39m@array_function_dispatch\u001b[39m(_moveaxis_dispatcher)\n\u001b[0;32m   1394\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmoveaxis\u001b[39m(a, source, destination):\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "class MyDataset(Dataset):\n",
    "\n",
    "    def __init__(self, folder) -> None:\n",
    "        super(Dataset, self).__init__()\n",
    "        self.data = []\n",
    "\n",
    "        for f in os.listdir(f'./{folder}/non'):\n",
    "            img_path = os.path.join(f'./{folder}/non', f)\n",
    "            img = cv2.imread(img_path)\n",
    "            img = img.astype(np.float32) / 255\n",
    "\n",
    "            mean = 0\n",
    "            sigma = 0.1\n",
    "            # 噪声数据\n",
    "            gauss = np.random.normal(mean,sigma,img.shape)\n",
    "            noisy_img = img + gauss\n",
    "\n",
    "            img = np.moveaxis(img, -1, 0)\n",
    "            noisy_img = np.moveaxis(noisy_img, -1, 0)\n",
    "            \n",
    "            self.data.append([img, 0])\n",
    "            self.data.append([noisy_img.astype(np.float32), 0])\n",
    "        \n",
    "        for f in os.listdir(f'./{folder}/white'):\n",
    "            img_path = os.path.join(f'./{folder}/white', f)\n",
    "            img = cv2.imread(img_path)\n",
    "            img = img.astype(np.float32) / 255\n",
    "            \n",
    "            mean = 0\n",
    "            sigma = 0.1\n",
    "            # 噪声数据\n",
    "            gauss = np.random.normal(mean,sigma,img.shape)\n",
    "            noisy_img = img + gauss\n",
    "\n",
    "            img = np.moveaxis(img, -1, 0)\n",
    "            noisy_img = np.moveaxis(noisy_img, -1, 0)\n",
    "\n",
    "            self.data.append([img, 1])\n",
    "            self.data.append([noisy_img.astype(np.float32), 1])\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return self.data.__len__()\n",
    "    \n",
    "    def __getitem__(self, index) -> (cv2.Mat, int):\n",
    "        return self.data[index][0], self.data[index][1]\n",
    "\n",
    "train_dataset = MyDataset('train_datasets')\n",
    "val_dataset = MyDataset('val_datasets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class cnn(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(cnn, self).__init__()\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=3,\n",
    "                out_channels=16,\n",
    "                kernel_size=3,\n",
    "                stride=2,\n",
    "            ),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "        )\n",
    "        #\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=16,\n",
    "                out_channels=32,\n",
    "                kernel_size=3,\n",
    "                stride=2,\n",
    "            ),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "        )\n",
    "        #\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=32,\n",
    "                out_channels=64,\n",
    "                kernel_size=3,\n",
    "                stride=2,\n",
    "            ),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "        )\n",
    "        self.conv4 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=64,\n",
    "                out_channels=16,\n",
    "                kernel_size=3,\n",
    "                stride=2,\n",
    "            ),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "        )\n",
    "        self.fc1 = nn.Linear(64, 32)\n",
    "        self.fc2 = nn.Linear(32, 10)\n",
    "        self.out = nn.Linear(10, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        # print(x.size())\n",
    "        x = x.contiguous().view(x.shape[0], -1)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        # x = self.relu(self.fc3(x))\n",
    "        # x = self.relu(self.fc4(x))\n",
    "        x = self.out(x)\n",
    "        # x = F.log_softmax(x, dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dtr = DataLoader(dataset=train_dataset, batch_size=50, shuffle=True, num_workers=0)\n",
    "Dva = DataLoader(dataset=val_dataset, batch_size=10, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import copy\n",
    "\n",
    "def get_val_loss(model, Val):\n",
    "    model.eval()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    val_loss = []\n",
    "    for (data, target) in Val:\n",
    "        data, target = Variable(data), Variable(target.long())\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        val_loss.append(loss.item())\n",
    "\n",
    "    return np.mean(val_loss)\n",
    "\n",
    "def train():\n",
    "    print('train...')\n",
    "    epoch_num = 50\n",
    "    best_model = None\n",
    "    min_epochs = 20\n",
    "    min_val_loss = 5\n",
    "    model = resnet18(num_classes=2)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.0008)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    # criterion = nn.BCELoss()\n",
    "    for epoch in tqdm(range(epoch_num), ascii=True):\n",
    "        train_loss = []\n",
    "        for batch_idx, (data, target) in enumerate(Dtr, 0):\n",
    "            data, target = Variable(data), Variable(target.long())\n",
    "            # target = target.view(target.shape[0], -1)\n",
    "            # print(data, target)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            # print(output)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss.append(loss.cpu().item())\n",
    "        # validation\n",
    "        val_loss = get_val_loss(model, Dva)\n",
    "        model.train()\n",
    "        if epoch + 1 > min_epochs and val_loss < min_val_loss:\n",
    "            min_val_loss = val_loss\n",
    "            best_model = copy.deepcopy(model)\n",
    "\n",
    "        tqdm.write('Epoch {:03d} train_loss {:.5f} val_loss {:.5f}'.format(epoch, np.mean(train_loss), val_loss))\n",
    "\n",
    "    torch.save(best_model.state_dict(), \"model/cnn.pkl\")\n",
    "    return best_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    \"\"\"Compute softmax values for each sets of scores in x.\"\"\"\n",
    "    e_x = np.exp(x - np.max(x))\n",
    "    return e_x / e_x.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [03:07<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\a1147\\Documents\\projects\\cnn\\train.ipynb Cell 6\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/a1147/Documents/projects/cnn/train.ipynb#W5sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m__name__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39m__main__\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/a1147/Documents/projects/cnn/train.ipynb#W5sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     train()\n",
      "\u001b[1;32mc:\\Users\\a1147\\Documents\\projects\\cnn\\train.ipynb Cell 6\u001b[0m line \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/a1147/Documents/projects/cnn/train.ipynb#W5sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m \u001b[39m# print(output)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/a1147/Documents/projects/cnn/train.ipynb#W5sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m loss \u001b[39m=\u001b[39m criterion(output, target)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/a1147/Documents/projects/cnn/train.ipynb#W5sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/a1147/Documents/projects/cnn/train.ipynb#W5sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/a1147/Documents/projects/cnn/train.ipynb#W5sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m train_loss\u001b[39m.\u001b[39mappend(loss\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mitem())\n",
      "File \u001b[1;32mc:\\Users\\a1147\\miniconda3\\Lib\\site-packages\\torch\\_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    482\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[0;32m    483\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    484\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[0;32m    485\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    490\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[0;32m    491\u001b[0m     )\n\u001b[1;32m--> 492\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[0;32m    493\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[0;32m    494\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\a1147\\miniconda3\\Lib\\site-packages\\torch\\autograd\\__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    246\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[0;32m    248\u001b[0m \u001b[39m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    249\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    250\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 251\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    252\u001b[0m     tensors,\n\u001b[0;32m    253\u001b[0m     grad_tensors_,\n\u001b[0;32m    254\u001b[0m     retain_graph,\n\u001b[0;32m    255\u001b[0m     create_graph,\n\u001b[0;32m    256\u001b[0m     inputs,\n\u001b[0;32m    257\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m    258\u001b[0m     accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m    259\u001b[0m )\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "model = resnet18(num_classes = 2)\n",
    "model.load_state_dict(torch.load('model/cnn (4).pkl'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.98945785 0.01054218]\n",
      "not weared!!\n",
      "[0.9831024  0.01689765]\n",
      "not weared!!\n",
      "[0.9762704  0.02372962]\n",
      "not weared!!\n",
      "[0.95596844 0.04403152]\n",
      "not weared!!\n",
      "[9.9960548e-01 3.9456697e-04]\n",
      "not weared!!\n",
      "[9.997193e-01 2.806109e-04]\n",
      "not weared!!\n",
      "[9.9957663e-01 4.2332767e-04]\n",
      "not weared!!\n",
      "[0.99675    0.00325004]\n",
      "not weared!!\n",
      "[9.999620e-01 3.806788e-05]\n",
      "not weared!!\n",
      "[9.994103e-01 5.897383e-04]\n",
      "not weared!!\n",
      "[0.97281367 0.0271864 ]\n",
      "not weared!!\n",
      "[0.8624624  0.13753754]\n",
      "not weared!!\n",
      "[9.9963176e-01 3.6826174e-04]\n",
      "not weared!!\n",
      "[0.9970367  0.00296326]\n",
      "not weared!!\n",
      "[0.91184646 0.08815354]\n",
      "not weared!!\n",
      "[0.9293943  0.07060574]\n",
      "not weared!!\n",
      "[0.7171148  0.28288516]\n",
      "not weared!!\n",
      "[0.99805    0.00195008]\n",
      "not weared!!\n",
      "[9.9999082e-01 9.1212405e-06]\n",
      "not weared!!\n",
      "[0.9964218  0.00357825]\n",
      "not weared!!\n",
      "[0.98893297 0.01106709]\n",
      "not weared!!\n",
      "[0.9833604  0.01663957]\n",
      "not weared!!\n",
      "[0.9852561  0.01474392]\n",
      "not weared!!\n",
      "[0.94979763 0.05020235]\n",
      "not weared!!\n",
      "[0.9370366  0.06296349]\n",
      "not weared!!\n",
      "[0.94543326 0.0545668 ]\n",
      "not weared!!\n",
      "[0.946681  0.0533189]\n",
      "not weared!!\n",
      "[0.9127671  0.08723288]\n",
      "not weared!!\n",
      "[0.9205841  0.07941594]\n",
      "not weared!!\n",
      "[0.88828015 0.11171981]\n",
      "not weared!!\n",
      "[0.90019214 0.09980781]\n",
      "not weared!!\n",
      "[0.9227416  0.07725844]\n",
      "not weared!!\n",
      "[0.90727866 0.09272127]\n",
      "not weared!!\n",
      "[9.9999905e-01 9.0834192e-07]\n",
      "not weared!!\n",
      "[9.999238e-01 7.616005e-05]\n",
      "not weared!!\n",
      "[9.99882579e-01 1.17356074e-04]\n",
      "not weared!!\n",
      "[9.9981242e-01 1.8759322e-04]\n",
      "not weared!!\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\a1147\\Documents\\projects\\cnn\\train.ipynb Cell 10\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/a1147/Documents/projects/cnn/train.ipynb#X12sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m cv2\u001b[39m.\u001b[39mimwrite(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mself-\u001b[39m\u001b[39m{\u001b[39;00mcnt\u001b[39m}\u001b[39;00m\u001b[39m.png\u001b[39m\u001b[39m'\u001b[39m, img)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/a1147/Documents/projects/cnn/train.ipynb#X12sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m cnt\u001b[39m+\u001b[39m\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/a1147/Documents/projects/cnn/train.ipynb#X12sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m time\u001b[39m.\u001b[39msleep(\u001b[39m1\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/a1147/Documents/projects/cnn/train.ipynb#X12sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m img \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mresize(img, (\u001b[39m224\u001b[39m, \u001b[39m224\u001b[39m))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/a1147/Documents/projects/cnn/train.ipynb#X12sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m data \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mmoveaxis(img, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m0\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "cnt = 0\n",
    "while(True):\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "\n",
    "    border_v = 0\n",
    "    border_h = 0\n",
    "    if (640/640) >= (frame.shape[0]/frame.shape[1]):\n",
    "        border_v = int((((640/640)*frame.shape[1])-frame.shape[0])/2)\n",
    "    else:\n",
    "        border_h = int((((640/640)*frame.shape[0])-frame.shape[1])/2)\n",
    "    img = cv2.copyMakeBorder(frame, border_v, border_v, border_h, border_h, cv2.BORDER_CONSTANT, 0)\n",
    "    img = cv2.resize(img, (640, 640))\n",
    "    cv2.imwrite(f'self-{cnt}.png', img)\n",
    "    cnt+=1\n",
    "    time.sleep(1)\n",
    "    img = cv2.resize(img, (224, 224))\n",
    "\n",
    "    data = np.moveaxis(img, -1, 0)\n",
    "    data = np.expand_dims(data, 0)\n",
    "    # print(data.shape)\n",
    "    data = torch.Tensor(data.astype(np.float32) / 255)\n",
    "    result = model(data)\n",
    "    # print(result[0])\n",
    "    print(softmax(result[0].detach().numpy()))\n",
    "    print('weared' if result[0][1] >= result[0][0] else 'not weared!!')\n",
    "\n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('frame', img)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# When everything done, release the capture\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "searchText = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(1, 3, 640, 640, requires_grad=True)\n",
    "torch.onnx.export(model, x, \"btest.onnx\",True, opset_version=10, input_names=['input'], output_names=['output'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
